<div align="center">

<a href="https://github.com/ystemsrx/mini-nanoGPT">
  <img src="https://img.shields.io/badge/NanoGPT-Mini-blueviolet?style=for-the-badge&logo=openai&logoColor=white" alt="Mini NanoGPT" height="30"/>
</a>

# ğŸš€ Mini NanoGPT

### *Training a GPT can really be this simple!*

[![Python](https://img.shields.io/badge/Python-3.7%2B-3776AB?style=flat-square&logo=python&logoColor=white)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-EE4C2C?style=flat-square&logo=pytorch&logoColor=white)](https://pytorch.org)
[![Gradio](https://img.shields.io/badge/Gradio-UI-FF6F00?style=flat-square&logo=gradio&logoColor=white)](https://gradio.app)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=flat-square&logo=docker&logoColor=white)](https://docker.com)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)

<p>
  <a href="https://github.com/ystemsrx/mini-nanoGPT"><strong>English</strong></a>
  Â·
  <a href="README.zh.md">ç®€ä½“ä¸­æ–‡</a>
</p>

<p>A visualized training platform upgraded from <a href="https://github.com/karpathy/nanoGPT">karpathy/nanoGPT</a>. <br/>Make GPT training fun and approachable!</p>

</div>

---

## ğŸ“– What is this?

Mini-NanoGPT is a tool that helps you get started with training GPT models effortlessly. Whether you're:

| ğŸ“ Beginner | ğŸ‘¨â€ğŸ”¬ Researcher | ğŸ› ï¸ Developer |
|:---:|:---:|:---:|
| Just starting deep learning | Experimenting with LLM architectures | Building AI-powered applications |

Or simply curious about large language models and want to experience their magic â€” you can train a model through an intuitive graphical interface!

> [!NOTE]
> For the original version of Mini NanoGPT (no longer updated), please check out the [**old** branch](https://github.com/ystemsrx/mini-nanoGPT/tree/old).

---

## âœ¨ Key Features

<table>
<tr>
<td width="50%">

### ğŸ¯ Easy to Use

- ğŸ“± **Visual Interface** â€” Say goodbye to command line
- ğŸŒ **Bilingual UI** â€” Full English & Chinese support
- ğŸ–±ï¸ **One-click Operations** â€” Data processing, training, and generation

</td>
<td width="50%">

### âš¡ Powerful Features

- ğŸ”¤ **Flexible Tokenization** â€” Character-level, GPT-2, or Qwen tokenizers
- ğŸš„ **Efficient Training** â€” Multi-process acceleration & distributed training
- ğŸ“Š **Real-time Feedback** â€” Live training progress and loss curves

</td>
</tr>
<tr>
<td>

### ğŸ§© Model Management

- âš™ï¸ **Parameter Visualization** â€” Adjust all training parameters in UI
- ğŸ—„ï¸ **Model Database** â€” Easily manage and reuse training settings
- ğŸ“‚ **Checkpoint Support** â€” Resume training from any saved state

</td>
<td>

### ğŸ“ SFT Training

- ğŸ’¬ **Supervised Fine-Tuning** â€” Train conversational AI models
- ğŸ“‹ **Alpaca Format** â€” Standard dataset format support
- ğŸ¤– **Chat Inference** â€” Interactive conversation with fine-tuned models

</td>
</tr>
</table>

---

## ğŸš€ Getting Started

### Option 1: Docker Deployment (Recommended) ğŸ³

> The easiest way to get started!

```bash
# Clone the repository
git clone --depth 1 https://github.com/ystemsrx/mini-nanoGPT.git
cd mini-nanoGPT

# Start with Docker Compose (recommended)
docker-compose up --build

# Or build and run manually
docker build -t mini-nanogpt .
docker run --gpus all -p 7860:7860 -v $(pwd)/data:/app/data mini-nanogpt
```

This will automatically build the Docker image and run the container. The container will detect your system environment (CPU/GPU) automatically. The `data`, `models`, and `assets` directories in the current working directory will be mounted into the container.

ğŸŒ Once started, visit **http://localhost:7860** to access the application.

For more details, please refer to [Docker Setup](docker/README.md).

---

### Option 2: Local Installation

```bash
# Clone the repository
git clone --depth 1 https://github.com/ystemsrx/mini-nanoGPT.git
cd mini-nanoGPT

# Install dependencies (Python 3.7+)
pip install -r requirements.txt

# Launch the app
python app.py
```

Open **http://localhost:7860** in your browser to see the training interface!

---

## ğŸ® User Guide

### Step 1: Prepare Data

Navigate to the **"Data Processing"** page, paste your training text, and choose a tokenization method.

> [!TIP]
> - For better results, enable the tokenizer option â€” it will automatically build a vocabulary based on your text
> - If you don't want to use a validation set, check the "Skip validation set" option

Click **"Start Processing"** when you're done.

#### Supported Data Formats

You can provide training data in multiple ways:

| Method | Description |
|--------|-------------|
| **Direct Input** | Paste text directly into the text box |
| **Directory Input** | Specify a directory path containing your data files |

**Directory Mode** supports **recursive scanning** of all subdirectories and the following file formats:

- **`.txt`** â€” Plain text files (entire file as one document)
- **`.jsonl`** â€” JSON Lines format with `{"text": "..."}` structure

<details>
<summary>ğŸ“ <strong>JSONL Format Example</strong></summary>

```jsonl
{"text": "This is the first document content."}
{"text": "This is the second document content."}
{"text": "Each line is treated as a separate document with EOT token appended."}
```

</details>

> [!NOTE]
> When using directory input, files of different formats (.txt and .jsonl) can be mixed in the same directory structure. All files will be processed correctly.

<details>
<summary>ğŸ“¸ <strong>View Screenshot</strong></summary>
<br/>
<img src="assets/imgs/en_data_process.png" alt="Data Processing" width="100%"/>
</details>

---

### Step 2: Train the Model

Switch to the **"Training"** page and adjust the parameters as needed (or leave them as default for a quick try).

- **Loss Curves**: Blue = Training Loss, Orange = Validation Loss
- If only one curve appears, check the terminal for block size errors â€” try reducing it to 128

<details>
<summary>ğŸ“¸ <strong>View Screenshot</strong></summary>
<br/>
<img src="assets/imgs/en_train.png" alt="Training" width="100%"/>
</details>

> [!NOTE]
> **Evaluation Mode Only?**  
> Set the `Number of Evaluation Seeds` to any value > 0 to activate evaluation-only mode. You'll see how the model performs with different random seeds.

---

### Step 3: Generate Text

Go to the **"Inference"** page, enter a prompt, and click **"Generate"** to see what the model comes up with!

<details>
<summary>ğŸ“¸ <strong>View Screenshot</strong></summary>
<br/>
<img src="assets/imgs/en_inference.png" alt="Inference" width="100%"/>
</details>

---

### Step 4: SFT Training (Fine-Tuning) ğŸ†•

The **Supervised Fine-Tuning (SFT)** feature allows you to fine-tune pre-trained models for conversational AI tasks.

#### How to Use SFT:

1. Navigate to the **"SFT"** page
2. Select a pre-trained base model from your model database
3. Import your dataset in **Alpaca format** (JSON file or directory)
4. Configure training parameters (learning rate, epochs, etc.)
5. Click **"Start Training"** to begin fine-tuning

<details>
<summary>ğŸ“¸ <strong>View SFT Training Screenshot</strong></summary>
<br/>
<img src="assets/imgs/en_sft.png" alt="SFT Training" width="100%"/>
</details>

#### Alpaca Dataset Format:

```json
[
  {
    "instruction": "What is the capital of France?",
    "input": "",
    "output": "The capital of France is Paris."
  },
  {
    "instruction": "Translate the following to Spanish:",
    "input": "Hello, how are you?",
    "output": "Hola, Â¿cÃ³mo estÃ¡s?"
  }
]
```

#### Chat with SFT Models:

After SFT training, go to the **"Inference"** page to have interactive conversations with your fine-tuned model!

<details>
<summary>ğŸ“¸ <strong>View SFT Inference Screenshot</strong></summary>
<br/>
<img src="assets/imgs/en_inference_sft.png" alt="SFT Inference" width="100%"/>
</details>

---

### Step 5: Model Comparison

Navigate to the **"Comparison"** page to compare two models side by side:

- Select two models (they can even be the same model with different settings)
- Their configurations will be displayed automatically
- Input the same prompt to see how both models generate text
- Compare outputs with different inference settings (temperature, top_k, etc.)

<details>
<summary>ğŸ“¸ <strong>View Screenshot</strong></summary>
<br/>
<img src="assets/imgs/en_comparison.png" alt="Comparison" width="100%"/>
</details>

---

## ğŸ“ Project Structure

```
mini-nanoGPT/
â”œâ”€â”€ ğŸ“„ app.py                 # Application entry point
â”œâ”€â”€ ğŸ“‚ src/                   # Source code modules
â”‚   â”œâ”€â”€ ğŸ“‚ ui/                # Gradio UI components
â”‚   â”‚   â”œâ”€â”€ app.py            # Main UI layout
â”‚   â”‚   â”œâ”€â”€ bindings/         # UI event bindings
â”‚   â”‚   â””â”€â”€ callbacks/        # UI callback functions
â”‚   â”œâ”€â”€ config.py             # Configuration management
â”‚   â”œâ”€â”€ data_process.py       # Data preprocessing
â”‚   â”œâ”€â”€ train.py              # Pre-training logic
â”‚   â”œâ”€â”€ sft.py                # SFT training module
â”‚   â”œâ”€â”€ infer.py              # Text generation
â”‚   â”œâ”€â”€ db_manager.py         # Model database management
â”‚   â””â”€â”€ gpt_model.py          # GPT model architecture
â”œâ”€â”€ ğŸ“‚ data/                  # Training data storage
â”œâ”€â”€ ğŸ“‚ out/                   # Model checkpoints
â”œâ”€â”€ ğŸ“‚ assets/                # Tokenizer files and resources
â””â”€â”€ ğŸ“‚ docker/                # Docker configuration files
```

---

## â“ FAQ

<details>
<summary><strong>ğŸ¢ Running too slowly?</strong></summary>

- ğŸ’¡ Reduce batch size or model size
- ğŸ’¡ Use a GPU to greatly improve speed
- ğŸ’¡ Increase the evaluation interval

</details>

<details>
<summary><strong>ğŸ“ Generated text isn't good?</strong></summary>

- ğŸ’¡ Try increasing the training data
- ğŸ’¡ Tune the model hyperparameters
- ğŸ’¡ Adjust the temperature during generation

</details>

<details>
<summary><strong>ğŸ”„ Want to resume previous training?</strong></summary>

- ğŸ’¡ On the "Training" page, select "resume" under Initialization
- ğŸ’¡ Point to the previous output directory

</details>

<details>
<summary><strong>ğŸ’¬ How to use SFT?</strong></summary>

- ğŸ’¡ First train a base model using pre-training
- ğŸ’¡ Prepare your dataset in Alpaca JSON format
- ğŸ’¡ Go to the SFT page and select your base model
- ğŸ’¡ Upload your dataset and start fine-tuning

</details>

---

## ğŸ¤ Contributing

Suggestions and improvements are welcome! You can:

- ğŸ› Submit an [Issue](https://github.com/ystemsrx/mini-nanoGPT/issues)
- ğŸ”§ Open a [Pull Request](https://github.com/ystemsrx/mini-nanoGPT/pulls)
- ğŸ’¬ Share your experience using the tool

---

## ğŸ“ License

This project is open-sourced under the [MIT License](LICENSE).

---

<div align="center">

### ğŸ‰ Start your GPT journey now!

<a href="https://github.com/ystemsrx/mini-nanoGPT">
  <img src="https://img.shields.io/badge/â­_Star_this_repo-if_you_find_it_useful!-yellow?style=for-the-badge" alt="Star"/>
</a>

</div>
