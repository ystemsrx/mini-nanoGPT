# config.py
import numpy as np
from multiprocessing import cpu_count

import torch
if torch.cuda.is_available():
    selected_device = "cuda:0"
    selected_backend = "nccl"
else:
    selected_device = "cpu"
    selected_backend = "gloo"


# Define the data type.
IntegerTypes = np.uint32

# Define default configuration values.
DEFAULT_CONFIG = {
    "data_process": {
        "train_split_ratio": 0.9,
        "no_validation": False,
        "use_gpt2_tokenizer": True,
        "num_proc": cpu_count() // 2
    },
    "training": {
        "out_dir": "out",
        "plot_interval": 10,
        "log_interval": 10,
        "num_eval_seeds": 0,
        "save_best_val_checkpoint": True,
        "init_from": "scratch",
        "gradient_accumulation_steps": 1,
        "batch_size": 32,
        "block_size": 256,
        "n_layer": 6,
        "n_head": 6,
        "n_embd": 384,
        "dropout": 0.1,
        "bias": True,
        "learning_rate": 1e-3,
        "max_iters": 300,
        "weight_decay": 1e-2,
        "beta1": 0.9,
        "beta2": 0.999,
        "lr_scheduler_type": "cosine",
        "warmup_iters": 10,
        "lr_decay_iters": 300,
        "min_lr": 1e-5,
        "step_size": 150,
        "step_gamma": 0.1,
        "polynomial_power": 2.0,
        "backend": selected_backend,
        "device": selected_device,
        "dtype": "float16",
        "compile_model": False,
        "seed": 1024,
        "save_interval": 50,
        # Self-attention specific parameters
        "use_self_attention": False,
        "ffn_hidden_mult": 4,
        "qkv_bias": True,
        "attn_dropout": 0.1,
        "resid_dropout": 0.1,
        "ln_eps": 1e-5,
        "init_std": 0.02,
        "use_flash_attn": False,
        "pos_encoding_type": "rope",
        "rope_base": 10000,
        "rope_cache_size": 1024,  # Dynamic RoPE cache size (None for auto)
        "alibi_bias_scale": 1.0,  # ALiBi bias scaling factor
        "ffn_activation": "gelu",  # FFN activation function: gelu, relu, swish
        "attention_scale_factor": 1.0,  # Additional attention scaling
        "gradient_checkpointing": False,  # Memory-efficient training
        # Memory management
        "cache_strategy": "adaptive",  # Cache allocation strategy: adaptive, fixed, minimal
        "max_cache_size": 4096,  # Maximum cache size for dynamic allocation
        # Error handling
        "strict_validation": True,  # Enable strict input validation
        "fallback_on_error": True  # Fallback to basic implementations on error
    },
    "inference": {
        "out_dir": "out",
        "prompt": "",
        "num_samples": 3,
        "max_new_tokens": 64,
        "temperature": 0.7,
        "top_k": 50,
        "seed": 1024,
        "device": selected_device,
        "dtype": "float16",
        "compile_model": False
    },
    "sft": {
        "dataset_path": "",
        "init_from": "scratch",
        "save_best_loss_checkpoint": True,
        "epochs": 3,
        "learning_rate": 2e-5,
        "batch_size": 4,
        "max_seq_length": 512,
        "gradient_accumulation_steps": 4,
        "lr_scheduler_type": "cosine",
        "warmup_iters": 0,
        "lr_decay_iters": 0,
        "min_lr": 1e-6,
        "step_size": 50,
        "step_gamma": 0.1,
        "polynomial_power": 2.0,
        "warmup_ratio": 0.1,
        "label_smoothing": 0.0,
        "freeze_layers": 0,
        "grad_clip": 1.0,
        "weight_decay": 0.01,
        "save_steps": 100,
        "logging_steps": 10,
        "system_prompt": "You are a helpful assistant."
    }
}

# Multilingual support
LANG_JSON = {
    "en": {
        "app_title": "Mini Nano GPT",
        "language_label": "Language",
        "data_process_tab": "Data Processing",
        "train_tab": "Pre-training",
        "infer_tab": "Inference",
        "compare_tab": "Comparison",
        "model_tab": "Model Management",

        "registered_models": "Registered Models",
        "refresh_tables": "Refresh",
        "delete_selected_model": "Delete Selected Model",

        "new_model": "New Model",
        "model_name": "Model Name",

        "dp_paste_text": "Paste Text",
        "dp_txt_dir": "TXT Directory (Optional)",
        "dp_raw_dir": "Raw Data Directory",
        "dp_processed_dir": "Processed Data Directory",
        "dp_train_split": "Training Split Ratio",
        "dp_no_val_set": "Do not use validation set",
        "dp_use_gpt2_tokenizer": "Use GPT-2/Qwen Tokenizer",
        "dp_num_proc": "Number of Processes",
        "dp_start_btn": "Start Processing",
        "dp_result": "Processing Result",

        "train_params_title": "Training Parameters",
        "train_data_dir": "Data Directory (where train.bin/val.bin)",
        "train_out_dir": "Output Directory",
        "train_eval_interval": "Plot Interval",
        "train_log_interval": "Logging Interval",
        "train_num_eval_seeds": "Number of Evaluation Seeds",
        "train_save_best_val_ckpt": "Save Best Val Loss Checkpoint",
        "train_init_from": "Initialization Source",
        "train_gas": "Gradient Accumulation Steps",
        "train_batch_size": "Batch Size",
        "train_block_size": "Block Size",
        "train_n_layer": "Number of Layers",
        "train_n_head": "Number of Attention Heads",
        "train_n_embd": "Embedding Dimension",
        "train_dropout": "Dropout Rate",
        "train_bias": "Use Bias",
        "train_lr": "Learning Rate",
        "train_max_iters": "Maximum Iterations",
        "train_weight_decay": "Weight Decay",
        "train_beta1": "Beta 1",
        "train_beta2": "Beta 2",
        "train_lr_scheduler": "Learning Rate Scheduler",
        "train_warmup_iters": "Warmup Iterations",
        "train_lr_decay_iters": "Learning Rate Decay Iterations",
        "train_min_lr": "Minimum Learning Rate",
        "train_step_size": "Step Size",
        "train_step_gamma": "Step Gamma",
        "train_poly_power": "Polynomial Power",
        "train_backend": "Backend",
        "train_device": "Device",
        "train_dtype": "Data Type",
        "train_compile_model": "Compile Model",
        "train_start_btn": "Start Training",
        "train_log": "Training Log",
        "train_plot": "Loss Curve",
        "train_seed": "Seed",
        "train_save_interval": "Save Interval (Steps)",

        # Self-attention parameters
        "train_self_attn_title": "Self-Attention Parameters",
        "train_use_self_attention": "Enable Self-Attention",
        "train_ffn_hidden_mult": "FFN Hidden Multiplier",
        "train_qkv_bias": "QKV Bias",
        "train_attn_dropout": "Attention Dropout",
        "train_resid_dropout": "Residual Dropout",
        "train_ln_eps": "Layer Norm Epsilon",
        "train_init_std": "Weight Init Std",
        "train_use_flash_attn": "Use Flash Attention",
        "train_pos_encoding_type": "Position Encoding",
        "train_rope_base": "RoPE Base",

        # New optimized parameters
        "train_rope_cache_size": "RoPE Cache Size",
        "train_alibi_bias_scale": "ALiBi Bias Scale",
        "train_ffn_activation": "FFN Activation",
        "train_attention_scale_factor": "Attention Scale",
        "train_gradient_checkpointing": "Gradient Checkpointing",
        "train_cache_strategy": "Cache Strategy",
        "train_max_cache_size": "Max Cache Size",
        "train_strict_validation": "Strict Validation",
        "train_fallback_on_error": "Fallback on Error",

        "inf_out_dir": "Model Directory (ckpt.pt)",
        "inf_prompt": "Prompt",
        "inf_num_samples": "Number of Samples",
        "inf_max_new_tokens": "Maximum New Tokens",
        "inf_temperature": "Temperature",
        "inf_top_k": "Top K",
        "inf_dtype": "Data Type",
        "inf_start_btn": "Generate",
        "inf_stop_btn": "Stop",
        "inf_result": "Generation Result",
        "inf_seed": "Seed",
        "inf_device": "Inference Device",
        "inf_advanced_output": "Detailed Information",
        "inf_token_position": "Position",
        "inf_selected_token": "Selected",
        "inf_top_candidates": "Top 5 Candidates",
        "inf_probability": "Probability",
        "inf_chat_tokenization": "User Input Tokenization",
        "inf_chat_advanced": "Chat Detailed Information",
        "inf_token_text": "Token",
        "inf_token_id": "Token ID",
        "inf_in_vocab": "In Vocab",
        "stop_btn": "Stop Training",

        "model_new": "Create New Model",
        "model_name": "Model Name",
        "model_description": "Description",
        "model_select": "Select Model",
        "model_create_btn": "Create",
        "model_delete_btn": "Delete",
        "model_save_btn": "Save",
        "model_list": "Model List",
        "model_current": "Current Model",
        "model_id": "ID",
        "model_create_time": "Created",
        "model_update_time": "Updated",
        "model_dir": "Directory",
        
        "compare_left_model": "Left",
        "compare_right_model": "Right",
        "compare_model_params": "Model Parameters",
        "compare_loss_curve": "Loss Curve",
        "compare_inference_history": "Inference History",
        "compare_inference_playground": "Playground",
        "compare_inference_params": "Inference Parameters",
        "compare_chat_mode": "Chat Mode (Both SFT)",
        "compare_generate_btn": "Generate",
        "compare_shared_prompt": "Shared Prompt",
        "compare_left_output": "Left Model Output",
        "compare_right_output": "Right Model Output",

        # SFT Tab
        "sft_tab": "SFT",
        "sft_title": "Supervised Fine-Tuning (SFT)",
        "sft_dataset_example": "Example Dataset Format",
        "sft_dataset_file": "Dataset File (JSON)",
        "sft_dataset_dir": "Dataset Directory",
        "sft_format_status": "Format Validation",
        "sft_validate_btn": "ğŸ” Validate Dataset",
        "sft_basic_params": "SFT Basic Parameters",
        "sft_optim_params": "Optimization & Regularization",
        "sft_scheduler_params": "Learning Rate Scheduler",
        "sft_epochs": "Epochs",
        "sft_learning_rate": "Learning Rate",
        "sft_batch_size": "Batch Size",
        "sft_max_seq_length": "Max Sequence Length",
        "sft_gradient_accumulation": "Gradient Accumulation Steps",
        "sft_init_from": "Initialization Source",
        "sft_save_best_loss_ckpt": "Save Best Loss Checkpoint",
        "sft_lr_scheduler": "Learning Rate Scheduler",
        "sft_warmup_iters": "Warmup Steps",
        "sft_lr_decay_iters": "LR Decay Steps",
        "sft_min_lr": "Minimum Learning Rate",
        "sft_step_size": "Step Size",
        "sft_step_gamma": "Step Gamma",
        "sft_poly_power": "Polynomial Power",
        "sft_label_smoothing": "Label Smoothing",
        "sft_freeze_layers": "Freeze Layers",
        "sft_grad_clip": "Gradient Clipping",
        "sft_weight_decay": "Weight Decay",
        "sft_system_prompt": "System Prompt",
        "sft_start_btn": "Start SFT Training",
        "sft_stop_btn": "Stop SFT",
        "sft_progress": "SFT Progress",
        "sft_log": "SFT Training Log",
        "sft_plot": "SFT Loss Curve",
        "sft_result": "SFT Result",
        "sft_valid_format": "âœ… Valid Alpaca Format",
        "sft_invalid_format": "âŒ Invalid Format",
        "sft_no_dataset": "No dataset loaded",
        "sft_dataset_example_json": (
            "[\n"
            "  {\n"
            "    \"instruction\": \"Why is the sky blue?\",\n"
            "    \"input\": \"\",\n"
            "    \"output\": \"The sky appears blue mainly due to Rayleigh scattering in the atmosphere...\"\n"
            "  },\n"
            "  {\n"
            "    \"instruction\": \"Please explain this concept:\",\n"
            "    \"input\": \"Relativity\",\n"
            "    \"output\": \"Relativity is a physical theory proposed by Albert Einstein...\"\n"
            "  },\n"
            "  {\n"
            "    \"instruction\": \"Summarize the following text:\",\n"
            "    \"input\": \"Neural networks are inspired by the brain and consist of layers of interconnected neurons.\",\n"
            "    \"output\": \"Neural networks are brain-inspired layered models made of connected neurons.\"\n"
            "  },\n"
            "  {\n"
            "    \"instruction\": \"Write a short greeting:\",\n"
            "    \"input\": \"\",\n"
            "    \"output\": \"Hello! How can I help you today?\"\n"
            "  }\n"
            "]"
        ),

        # Chat Mode
        "inf_chat_mode": "Chat Mode (for SFT models)",
        "inf_chat_history": "Conversation History",
        "inf_user_input": "Your Message",
        "inf_send_btn": "Send",
        "inf_clear_chat": "Clear Chat",
        "inf_system_prompt": "System Prompt"
    },
    "zh": {
        "app_title": "Mini Nano GPT",
        "language_label": "è¯­è¨€",
        "data_process_tab": "æ•°æ®å¤„ç†",
        "train_tab": "é¢„è®­ç»ƒ",
        "infer_tab": "æ¨ç†",
        "compare_tab": "å¯¹æ¯”",
        "model_tab": "æ¨¡å‹ç®¡ç†",

        "registered_models": "å·²æ³¨å†Œæ¨¡å‹",
        "refresh_tables": "åˆ·æ–°",
        "delete_selected_model": "åˆ é™¤é€‰ä¸­æ¨¡å‹",

        "new_model": "æ–°æ¨¡å‹",
        "model_name": "æ¨¡å‹åç§°",

        "dp_paste_text": "ç²˜è´´æ–‡æœ¬",
        "dp_txt_dir": "TXTæ–‡ä»¶ç›®å½•ï¼ˆå¯é€‰ï¼‰",
        "dp_raw_dir": "åŸå§‹æ•°æ®ç›®å½•",
        "dp_processed_dir": "å¤„ç†åæ•°æ®ç›®å½•",
        "dp_train_split": "è®­ç»ƒé›†æ¯”ä¾‹ (Training Split Ratio)",
        "dp_no_val_set": "æš‚ä¸éœ€è¦éªŒè¯é›†",
        "dp_use_gpt2_tokenizer": "ä½¿ç”¨ GPT-2/Qwen åˆ†è¯å™¨ (Use GPT-2/Qwen Tokenizer)",
        "dp_num_proc": "è¿›ç¨‹æ•° (Number of processes)",
        "dp_start_btn": "å¼€å§‹å¤„ç†",
        "dp_result": "å¤„ç†ç»“æœ",

        "train_params_title": "è®­ç»ƒå‚æ•° (Training Parameters)",
        "train_data_dir": "æ•°æ®ç›®å½•ï¼ˆåŒ…å« train.bin/val.binï¼‰",
        "train_out_dir": "è¾“å‡ºç›®å½•",
        "train_eval_interval": "è¯„ä¼°é—´éš” (Plot Interval)",
        "train_log_interval": "æ—¥å¿—é—´éš” (Logging Interval)",
        "train_num_eval_seeds": "è¯„ä¼°ç§å­æ•°é‡ (Number of Evaluation Seeds)",
        "train_save_best_val_ckpt": "ä¿å­˜éªŒè¯æŸå¤±æœ€ä½³ç‚¹ (Save Best Val Loss Checkpoint)",
        "train_init_from": "åˆå§‹åŒ–æ–¹å¼ (Initialization Source)",
        "train_gas": "æ¢¯åº¦ç´¯ç§¯æ­¥æ•° (Gradient Accumulation Steps)",
        "train_batch_size": "æ‰¹é‡å¤§å° (Batch Size)",
        "train_block_size": "å—/ä¸Šä¸‹æ–‡å¤§å° (Block Size)",
        "train_n_layer": "å±‚æ•° (Number of Layers)",
        "train_n_head": "å¤´æ•° (Number of Attention Heads)",
        "train_n_embd": "åµŒå…¥ç»´åº¦ (Embedding Dimension)",
        "train_dropout": "ä¸¢å¼ƒç‡ (Dropout Rate)",
        "train_bias": "æ˜¯å¦ä½¿ç”¨åç½®ï¼Ÿ (Use Bias)",
        "train_lr": "å­¦ä¹ ç‡ (Learning Rate)",
        "train_max_iters": "æœ€å¤§è¿­ä»£æ¬¡æ•° (Maximum Iterations)",
        "train_weight_decay": "æƒé‡è¡°å‡ (Weight Decay)",
        "train_beta1": "Î²1 (Beta 1)",
        "train_beta2": "Î²2 (Beta 2)",
        "train_lr_scheduler": "å­¦ä¹ ç‡è°ƒåº¦å™¨ (Learning Rate Scheduler)",
        "train_warmup_iters": "é¢„çƒ­è¿­ä»£æ¬¡æ•° (Warmup Iterations)",
        "train_lr_decay_iters": "å­¦ä¹ ç‡è¡°å‡è¿­ä»£æ¬¡æ•° (Learning Rate Decay Iterations)",
        "train_min_lr": "æœ€å°å­¦ä¹ ç‡ (Minimum Learning Rate)",
        "train_step_size": "æ­¥é•¿ (Step Size)",
        "train_step_gamma": "è¡°å‡ç‡ (Step Gamma)",
        "train_poly_power": "è¡°å‡æŒ‡æ•° (Polynomial Power)",
        "train_backend": "åç«¯ (Backend)",
        "train_device": "è®¾å¤‡ (Device)",
        "train_dtype": "æ•°æ®ç±»å‹ (Data Type)",
        "train_compile_model": "ç¼–è¯‘æ¨¡å‹ (Compile Model)",
        "train_start_btn": "å¼€å§‹è®­ç»ƒ",
        "train_log": "è®­ç»ƒæ—¥å¿— (Training Log)",
        "train_plot": "æŸå¤±æ›²çº¿ (Loss Curve)",
        "train_seed": "ç§å­ (Seed)",
        "train_save_interval": "ä¿å­˜é—´éš” (Save Interval)",

        # Self-attention parameters
        "train_self_attn_title": "è‡ªæ³¨æ„åŠ›å‚æ•° (Self-Attention Parameters)",
        "train_use_self_attention": "å¯ç”¨è‡ªæ³¨æ„åŠ› (Enable Self-Attention)",
        "train_ffn_hidden_mult": "FFNéšè—å±‚å€æ•° (FFN Hidden Multiplier)",
        "train_qkv_bias": "QKVåç½® (QKV Bias)",
        "train_attn_dropout": "æ³¨æ„åŠ›ä¸¢å¼ƒç‡ (Attention Dropout)",
        "train_resid_dropout": "æ®‹å·®ä¸¢å¼ƒç‡ (Residual Dropout)",
        "train_ln_eps": "å±‚å½’ä¸€åŒ–ç²¾åº¦ (Layer Norm Epsilon)",
        "train_init_std": "æƒé‡åˆå§‹åŒ–æ ‡å‡†å·® (Weight Init Std)",
        "train_use_flash_attn": "ä½¿ç”¨ Flash Attention (Use Flash Attention)",
        "train_pos_encoding_type": "ä½ç½®ç¼–ç ç±»å‹ (Position Encoding)",
        "train_rope_base": "RoPEåŸºæ•° (RoPE Base)",

        # New optimized parameters
        "train_rope_cache_size": "RoPEç¼“å­˜å¤§å° (RoPE Cache Size)",
        "train_alibi_bias_scale": "ALiBiåç½®ç¼©æ”¾ (ALiBi Bias Scale)",
        "train_ffn_activation": "FFNæ¿€æ´»å‡½æ•° (FFN Activation)",
        "train_attention_scale_factor": "æ³¨æ„åŠ›ç¼©æ”¾å› å­ (Attention Scale)",
        "train_gradient_checkpointing": "æ¢¯åº¦æ£€æŸ¥ç‚¹ (Gradient Checkpointing)",
        "train_cache_strategy": "ç¼“å­˜ç­–ç•¥ (Cache Strategy)",
        "train_max_cache_size": "æœ€å¤§ç¼“å­˜å¤§å° (Max Cache Size)",
        "train_strict_validation": "ä¸¥æ ¼éªŒè¯ (Strict Validation)",
        "train_fallback_on_error": "é”™è¯¯å›é€€ (Fallback on Error)",

        "inf_out_dir": "æ¨¡å‹ç›®å½•ï¼ˆckpt.ptï¼‰",
        "inf_prompt": "æç¤ºè¯ (Prompt)",
        "inf_num_samples": "ç”Ÿæˆæ ·æœ¬æ•° (Number of Samples)",
        "inf_max_new_tokens": "æœ€å¤šç”Ÿæˆæ ‡è®°æ•° (Maximum New Tokens)",
        "inf_temperature": "æ¸©åº¦ (Temperature)",
        "inf_top_k": "TOP K",
        "inf_dtype": "æ•°æ®ç±»å‹ (Data Type)",
        "inf_start_btn": "å¼€å§‹ç”Ÿæˆ",
        "inf_stop_btn": "ç»ˆæ­¢",
        "inf_result": "ç”Ÿæˆç»“æœ",
        "inf_seed": "ç§å­ (Seed)",
        "inf_device": "æ¨ç†è®¾å¤‡ (Inference Device)",
        "inf_advanced_output": "è¯¦ç»†ä¿¡æ¯",
        "inf_token_position": "ä½ç½®",
        "inf_selected_token": "å·²é€‰token",
        "inf_top_candidates": "å‰5å€™é€‰",
        "inf_probability": "æ¦‚ç‡",
        "inf_chat_tokenization": "ç”¨æˆ·è¾“å…¥åˆ†è¯",
        "inf_chat_advanced": "å¯¹è¯è¯¦ç»†ä¿¡æ¯",
        "inf_token_text": "Token",
        "inf_token_id": "Token ID",
        "inf_in_vocab": "è¯è¡¨å†…",
        "stop_btn": "åœæ­¢è®­ç»ƒ",

        "model_new": "åˆ›å»ºæ–°æ¨¡å‹",
        "model_name": "æ¨¡å‹åç§°",
        "model_description": "æè¿°",
        "model_select": "é€‰æ‹©æ¨¡å‹",
        "model_create_btn": "åˆ›å»º",
        "model_delete_btn": "åˆ é™¤",
        "model_save_btn": "ä¿å­˜",
        "model_list": "æ¨¡å‹åˆ—è¡¨",
        "model_current": "å½“å‰æ¨¡å‹",
        "model_id": "ID",
        "model_create_time": "åˆ›å»ºæ—¶é—´",
        "model_update_time": "æ›´æ–°æ—¶é—´",
        "model_dir": "ç›®å½•",
        
        "compare_left_model": "å·¦ä¾§",
        "compare_right_model": "å³ä¾§",
        "compare_model_params": "æ¨¡å‹å‚æ•° (Model Parameters)",
        "compare_loss_curve": "æŸå¤±æ›²çº¿ (Loss Curve)",
        "compare_inference_history": "æ¨ç†å†å²",
        "compare_inference_playground": "Playground",
        "compare_inference_params": "æ¨ç†å‚æ•°",
        "compare_chat_mode": "å¯¹è¯æ¨¡å¼ï¼ˆéœ€ä¸¤ä¸ªæ¨¡å‹éƒ½SFTï¼‰",
        "compare_generate_btn": "ç”Ÿæˆ (Generate)",
        "compare_shared_prompt": "æç¤ºè¯ (Shared Prompt)",
        "compare_left_output": "å·¦ä¾§æ¨¡å‹è¾“å‡º",
        "compare_right_output": "å³ä¾§æ¨¡å‹è¾“å‡º",

        # SFT Tab
        "sft_tab": "SFTå¾®è°ƒ",
        "sft_title": "ç›‘ç£å¾®è°ƒ (SFT)",
        "sft_dataset_example": "ç¤ºä¾‹æ•°æ®é›†æ ¼å¼",
        "sft_dataset_file": "æ•°æ®é›†æ–‡ä»¶ (JSON)",
        "sft_dataset_dir": "æ•°æ®é›†ç›®å½•",
        "sft_format_status": "æ ¼å¼éªŒè¯",
        "sft_validate_btn": "ğŸ” éªŒè¯æ•°æ®é›†",
        "sft_basic_params": "SFTåŸºç¡€å‚æ•°",
        "sft_optim_params": "ä¼˜åŒ–ä¸æ­£åˆ™åŒ–",
        "sft_scheduler_params": "å­¦ä¹ ç‡è°ƒåº¦å™¨",
        "sft_epochs": "è®­ç»ƒè½®æ•° (Epochs)",
        "sft_learning_rate": "å­¦ä¹ ç‡ (Learning Rate)",
        "sft_batch_size": "æ‰¹é‡å¤§å° (Batch Size)",
        "sft_max_seq_length": "æœ€å¤§åºåˆ—é•¿åº¦ (Max Sequence Length)",
        "sft_gradient_accumulation": "æ¢¯åº¦ç´¯ç§¯æ­¥æ•° (Gradient Accumulation)",
        "sft_init_from": "åˆå§‹åŒ–æ–¹å¼ (Initialization Source)",
        "sft_save_best_loss_ckpt": "ä¿å­˜æŸå¤±æœ€ä½³ç‚¹ (Save Best Loss Checkpoint)",
        "sft_lr_scheduler": "å­¦ä¹ ç‡è°ƒåº¦å™¨",
        "sft_warmup_iters": "é¢„çƒ­æ­¥æ•° (Warmup Steps)",
        "sft_lr_decay_iters": "å­¦ä¹ ç‡è¡°å‡æ­¥æ•° (LR Decay Steps)",
        "sft_min_lr": "æœ€å°å­¦ä¹ ç‡ (Minimum LR)",
        "sft_step_size": "é˜¶æ¢¯æ­¥é•¿ (Step Size)",
        "sft_step_gamma": "é˜¶æ¢¯è¡°å‡ (Step Gamma)",
        "sft_poly_power": "å¤šé¡¹å¼å¹‚ (Polynomial Power)",
        "sft_label_smoothing": "æ ‡ç­¾å¹³æ»‘ (Label Smoothing)",
        "sft_freeze_layers": "å±‚å†»ç»“ (Freeze Layers)",
        "sft_grad_clip": "æ¢¯åº¦è£å‰ª (Gradient Clipping)",
        "sft_weight_decay": "æƒé‡è¡°å‡ (Weight Decay)",
        "sft_system_prompt": "ç³»ç»Ÿæç¤ºè¯ (System Prompt)",
        "sft_start_btn": "å¼€å§‹SFTè®­ç»ƒ",
        "sft_stop_btn": "åœæ­¢SFT",
        "sft_progress": "SFTè¿›åº¦",
        "sft_log": "SFTè®­ç»ƒæ—¥å¿—",
        "sft_plot": "SFTæŸå¤±æ›²çº¿",
        "sft_result": "SFTç»“æœ",
        "sft_valid_format": "âœ… Alpacaæ ¼å¼æœ‰æ•ˆ",
        "sft_invalid_format": "âŒ æ ¼å¼æ— æ•ˆ",
        "sft_no_dataset": "æœªåŠ è½½æ•°æ®é›†",
        "sft_dataset_example_json": (
            "[\n"
            "  {\n"
            "    \"instruction\": \"å¤©ç©ºä¸ºä»€ä¹ˆæ˜¯è“è‰²çš„ï¼Ÿ\",\n"
            "    \"input\": \"\",\n"
            "    \"output\": \"å¤©ç©ºä¹‹æ‰€ä»¥å‘ˆç°è“è‰²ï¼Œä¸»è¦æ˜¯ç”±äºå¤§æ°”æ•£å°„ç°è±¡...\"\n"
            "  },\n"
            "  {\n"
            "    \"instruction\": \"è¯·è§£é‡Šæ­¤æ¦‚å¿µï¼š\",\n"
            "    \"input\": \"ç›¸å¯¹è®º\",\n"
            "    \"output\": \"ç›¸å¯¹è®ºæ˜¯ç”±é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦æå‡ºçš„ç‰©ç†å­¦ç†è®º...\"\n"
            "  },\n"
            "  {\n"
            "    \"instruction\": \"è¯·æ€»ç»“ä¸‹é¢è¿™æ®µè¯ï¼š\",\n"
            "    \"input\": \"ç¥ç»ç½‘ç»œå—å¤§è„‘å¯å‘ï¼Œç”±å¤šå±‚ç›¸äº’è¿æ¥çš„ç¥ç»å…ƒç»„æˆã€‚\",\n"
            "    \"output\": \"ç¥ç»ç½‘ç»œæ˜¯ç”±å¤šå±‚äº’è”ç¥ç»å…ƒæ„æˆçš„è„‘å¯å‘æ¨¡å‹ã€‚\"\n"
            "  },\n"
            "  {\n"
            "    \"instruction\": \"å†™ä¸€å¥ç®€çŸ­çš„é—®å€™ï¼š\",\n"
            "    \"input\": \"\",\n"
            "    \"output\": \"ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æä¾›å¸®åŠ©ã€‚\"\n"
            "  }\n"
            "]"
        ),

        # Chat Mode
        "inf_chat_mode": "å¯¹è¯æ¨¡å¼ï¼ˆç”¨äºSFTæ¨¡å‹ï¼‰",
        "inf_chat_history": "å¯¹è¯å†å²",
        "inf_user_input": "æ‚¨çš„æ¶ˆæ¯",
        "inf_send_btn": "å‘é€",
        "inf_clear_chat": "æ¸…ç©ºå¯¹è¯",
        "inf_system_prompt": "ç³»ç»Ÿæç¤ºè¯"
    }
}
