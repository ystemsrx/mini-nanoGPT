import gradio as gr

from src.config import LANG_JSON


def switch_language(lang_code: str):
    Tn = LANG_JSON[lang_code]

    return [
        gr.update(label=Tn["language_label"], value=lang_code),
        # Tab labels
        gr.update(label=Tn["data_process_tab"]),
        gr.update(label=Tn["train_tab"]),
        gr.update(label=Tn["infer_tab"]),
        gr.update(label=Tn["compare_tab"]),
        # Top bar
        gr.update(label=Tn["registered_models"]),
        gr.update(value=Tn["refresh_tables"]),
        gr.update(value=Tn["delete_selected_model"]),
        # Model management (Data Processing Tab)
        gr.update(label=Tn["new_model"]),
        gr.update(label=Tn["model_name"]),
        # Data processing panel
        gr.update(label=Tn["dp_paste_text"]),
        gr.update(label=Tn["dp_txt_dir"]),
        gr.update(label=Tn["dp_no_val_set"]),
        gr.update(label=Tn["dp_use_gpt2_tokenizer"]),
        gr.update(label=Tn["dp_train_split"]),
        gr.update(label=Tn["dp_num_proc"]),
        gr.update(value=Tn["dp_start_btn"]),
        gr.update(label=Tn["dp_result"]),
        # Training panel
        gr.update(value=f"### {Tn['train_params_title']}"),
        gr.update(label=Tn["train_data_dir"]),
        gr.update(label=Tn["train_out_dir"]),
        gr.update(label=Tn["train_backend"]),
        gr.update(label=Tn["train_device"]),
        gr.update(label=Tn["train_dtype"]),
        gr.update(label=Tn["train_compile_model"]),
        gr.update(label=Tn["train_eval_interval"]),
        gr.update(label=Tn["train_log_interval"]),
        gr.update(label=Tn["train_num_eval_seeds"]),
        gr.update(label=Tn["train_save_best_val_ckpt"]),
        gr.update(label=Tn["train_init_from"]),
        gr.update(label=Tn["train_seed"]),
        gr.update(label=Tn["train_gas"]),
        gr.update(label=Tn["train_batch_size"]),
        gr.update(label=Tn["train_block_size"]),
        gr.update(label=Tn["train_n_layer"]),
        gr.update(label=Tn["train_n_head"]),
        gr.update(label=Tn["train_n_embd"]),
        gr.update(label=Tn["train_dropout"]),
        gr.update(label=Tn["train_bias"]),
        gr.update(label=Tn["train_lr"]),
        gr.update(label=Tn["train_max_iters"]),
        gr.update(label=Tn["train_weight_decay"]),
        gr.update(label=Tn["train_beta1"]),
        gr.update(label=Tn["train_beta2"]),
        gr.update(label=Tn["train_lr_scheduler"]),
        gr.update(label=Tn["train_warmup_iters"]),
        gr.update(label=Tn["train_lr_decay_iters"]),
        gr.update(label=Tn["train_min_lr"]),
        gr.update(label=Tn["train_step_size"]),
        gr.update(label=Tn["train_step_gamma"]),
        gr.update(label=Tn["train_poly_power"]),
        gr.update(label=Tn["train_save_interval"]),
        gr.update(value=Tn["train_start_btn"]),
        gr.update(value=Tn["stop_btn"]),
        gr.update(label=Tn["train_log"]),
        gr.update(label=Tn["train_plot"]),
        # Inference panel
        gr.update(label=Tn["dp_processed_dir"]),
        gr.update(label=Tn["inf_out_dir"]),
        gr.update(label=Tn["inf_prompt"]),
        gr.update(label=Tn["inf_num_samples"]),
        gr.update(label=Tn["inf_max_new_tokens"]),
        gr.update(label=Tn["inf_temperature"]),
        gr.update(label=Tn["inf_top_k"]),
        gr.update(label=Tn["inf_dtype"]),
        gr.update(label=Tn["inf_device"]),
        gr.update(label=Tn["inf_seed"]),
        gr.update(value=Tn["inf_start_btn"]),
        gr.update(label=Tn["inf_result"]),
        gr.update(label=Tn["inf_advanced_output"]),
        gr.update(label=Tn["inf_advanced_output"]),
        # Chat mode components
        gr.update(label=Tn["inf_chat_mode"]),
        gr.update(label=Tn["inf_chat_history"]),
        gr.update(label=Tn["inf_system_prompt"]),
        gr.update(label=Tn["inf_user_input"]),
        gr.update(value=Tn["inf_send_btn"]),
        gr.update(value=Tn["inf_clear_chat"]),
        gr.update(label=Tn["inf_chat_advanced"]),
        gr.update(label=Tn["inf_advanced_output"]),
        # Comparison tab
        gr.update(label=Tn["compare_left_model"]),
        gr.update(label=Tn["compare_right_model"]),
        gr.update(label=Tn["compare_model_params"]),
        gr.update(label=Tn["compare_model_params"]),
        gr.update(label=Tn["compare_loss_curve"]),
        gr.update(label=Tn["compare_loss_curve"]),
        gr.update(label=Tn["compare_inference_history"]),
        gr.update(label=Tn["compare_inference_history"]),
        # Left model params
        gr.update(label=Tn["inf_num_samples"]),
        gr.update(label=Tn["inf_max_new_tokens"]),
        gr.update(label=Tn["inf_temperature"]),
        gr.update(label=Tn["inf_top_k"]),
        gr.update(label=Tn["inf_dtype"]),
        gr.update(label=Tn["inf_seed"]),
        # Right model params
        gr.update(label=Tn["inf_num_samples"]),
        gr.update(label=Tn["inf_max_new_tokens"]),
        gr.update(label=Tn["inf_temperature"]),
        gr.update(label=Tn["inf_top_k"]),
        gr.update(label=Tn["inf_dtype"]),
        gr.update(label=Tn["inf_seed"]),
        gr.update(label=Tn["compare_shared_prompt"]),
        gr.update(value=Tn["compare_generate_btn"]),
        gr.update(label=Tn["compare_left_output"]),
        gr.update(label=Tn["compare_right_output"]),
        # Self-attention parameters
        gr.update(label=Tn["train_self_attn_title"]),
        gr.update(label=Tn["train_use_self_attention"]),
        gr.update(label=Tn["train_ffn_hidden_mult"]),
        gr.update(label=Tn["train_qkv_bias"]),
        gr.update(label=Tn["train_attn_dropout"]),
        gr.update(label=Tn["train_resid_dropout"]),
        gr.update(label=Tn["train_ln_eps"]),
        gr.update(label=Tn["train_init_std"]),
        gr.update(label=Tn["train_use_flash_attn"]),
        gr.update(label=Tn["train_pos_encoding_type"]),
        gr.update(label=Tn["train_rope_base"]),
        # New optimized parameters
        gr.update(label=Tn["train_rope_cache_size"]),
        gr.update(label=Tn["train_alibi_bias_scale"]),
        gr.update(label=Tn["train_ffn_activation"]),
        gr.update(label=Tn["train_attention_scale_factor"]),
        gr.update(label=Tn["train_gradient_checkpointing"]),
        gr.update(label=Tn["train_cache_strategy"]),
        gr.update(label=Tn["train_max_cache_size"]),
        gr.update(label=Tn["train_strict_validation"]),
        gr.update(label=Tn["train_fallback_on_error"]),
        # SFT tab
        gr.update(label=Tn["sft_tab"]),
        gr.update(value=f"### {Tn['sft_title']}"),
        gr.update(label=Tn["sft_basic_params"]),
        gr.update(label=Tn["sft_optim_params"]),
        gr.update(label=Tn["sft_scheduler_params"]),
        gr.update(label=Tn["sft_dataset_example"], value=Tn["sft_dataset_example_json"]),
        gr.update(label=Tn["sft_dataset_file"]),
        gr.update(label=Tn["sft_dataset_dir"]),
        gr.update(label=Tn["sft_format_status"]),
        gr.update(value=Tn["sft_validate_btn"]),
        gr.update(label=Tn["sft_init_from"]),
        gr.update(label=Tn["sft_save_best_loss_ckpt"]),
        gr.update(label=Tn["sft_epochs"]),
        gr.update(label=Tn["sft_learning_rate"]),
        gr.update(label=Tn["sft_batch_size"]),
        gr.update(label=Tn["sft_max_seq_length"]),
        gr.update(label=Tn["sft_gradient_accumulation"]),
        gr.update(label=Tn["sft_lr_scheduler"]),
        gr.update(label=Tn["sft_warmup_iters"]),
        gr.update(label=Tn["sft_lr_decay_iters"]),
        gr.update(label=Tn["sft_min_lr"]),
        gr.update(label=Tn["sft_step_size"]),
        gr.update(label=Tn["sft_step_gamma"]),
        gr.update(label=Tn["sft_poly_power"]),
        gr.update(label=Tn["sft_label_smoothing"]),
        gr.update(label=Tn["sft_freeze_layers"]),
        gr.update(label=Tn["sft_grad_clip"]),
        gr.update(label=Tn["sft_weight_decay"]),
        gr.update(label=Tn["sft_system_prompt"]),
        gr.update(value=Tn["sft_start_btn"]),
        gr.update(value=Tn["sft_stop_btn"]),
        gr.update(label=Tn["sft_progress"]),
        gr.update(label=Tn["sft_log"]),
        gr.update(label=Tn["sft_plot"]),
    ]
